{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bacfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for the notebooks, the cwd needs to be set to the root of the project\n",
    "import os\n",
    "from pathlib import Path\n",
    "home = Path.home()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "if not 'initial_cwd' in locals():\n",
    "\tinitial_cwd = cwd\n",
    "\n",
    "# check if any of the parent directories is 'notebooks'\n",
    "relative_path = Path(cwd).relative_to(home)\n",
    "if 'notebooks' in relative_path.parts:\n",
    "\t# if so, change the current working directory to the root of the project\n",
    "\twhile relative_path.parts and not 'notebooks' in os.listdir(cwd):\n",
    "\t\tcwd = os.path.dirname(cwd)\n",
    "\t\trelative_path = Path(cwd).relative_to(home)\n",
    "\tif 'notebooks' in os.listdir(cwd):\n",
    "\t\tos.chdir(cwd)\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Initial working directory: {initial_cwd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt --quiet\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbd686",
   "metadata": {},
   "source": [
    "# Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019eab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from LoggingColor import ColorHandler\n",
    "import sys\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s.%(msecs)03d %(name)-16s [%(levelname)-1s]: %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f'log.log',mode='w'),\n",
    "        #logging.StreamHandler(sys.stdout),\n",
    "        ColorHandler(sys.stdout)\n",
    "    ],\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.debug(\"Debug log test\")\n",
    "logger.info(\"Info log test\")\n",
    "logger.warning(\"Warning log test\")\n",
    "logger.error(\"Error log test\")\n",
    "logger.critical(\"Critical log test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf91ba",
   "metadata": {},
   "source": [
    "# Fetch magisk releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21d57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class MagiskRelease:\n",
    "    tag_name: str\n",
    "    release_name: str\n",
    "    prerelease: bool\n",
    "    debug: bool\n",
    "    filename: str\n",
    "    url: str\n",
    "\n",
    "    def download(self, download_dir: str, filename: str = None, overwrite: bool = False) -> str:\n",
    "        import requests\n",
    "        import os\n",
    "        from tqdm.auto import tqdm\n",
    "\n",
    "        if filename is None:\n",
    "            filename = self.filename\n",
    "\n",
    "        os.makedirs(download_dir, exist_ok=True)\n",
    "        out_path = os.path.join(download_dir, filename)\n",
    "\n",
    "        if not overwrite and os.path.exists(out_path):\n",
    "            logger.warning(f\"File {out_path} already exists, skipping download.\")\n",
    "            return out_path\n",
    "\n",
    "        logger.info(f\"Downloading magisk {self.tag_name} to {out_path}\")\n",
    "        temp_path = out_path + \".part\"\n",
    "        with requests.get(self.url, stream=True) as r:\n",
    "            total_size = int(r.headers.get('content-length', 0))\n",
    "            with tqdm(total=total_size, unit='B', unit_scale=True, desc=filename) as pbar:\n",
    "                with open(temp_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                        pbar.update(len(chunk))\n",
    "            assert total_size == os.path.getsize(temp_path), f\"Downloaded file size {os.path.getsize(temp_path)} does not match expected size {total_size}\"\n",
    "\n",
    "        os.rename(temp_path, out_path)\n",
    "\n",
    "        return out_path\n",
    "\n",
    "def fetchMagiskReleases() -> list[MagiskRelease]:\n",
    "    import requests\n",
    "    import re\n",
    "\n",
    "    with requests.Session() as s:\n",
    "        headers = {\n",
    "            'X-GitHub-Api-Version': '2022-11-28',\n",
    "            'Accept': 'application/vnd.github+json',\n",
    "        }\n",
    "\n",
    "        res = s.get(\"https://api.github.com/repos/topjohnwu/Magisk/releases\", headers=headers)\n",
    "\n",
    "    assert res.status_code == 200, f\"Failed to fetch OTA page: {res.status_code}\"\n",
    "\n",
    "    releases = res.json()\n",
    "    logger.info(f\"Found {len(releases)} releases\")\n",
    "    available_releases = []\n",
    "    for release in releases:\n",
    "        tag_name = release['tag_name']\n",
    "        release_name = release['name']\n",
    "        prerelease = release['prerelease']\n",
    "        for asset in release['assets']:\n",
    "            filename = asset['name']\n",
    "\n",
    "            url = asset['browser_download_url']\n",
    "            if not filename.endswith('.apk'):\n",
    "                logger.debug(f\"Skipping non-apk asset: {filename}\")\n",
    "                continue\n",
    "            \n",
    "            # remove some dud file names\n",
    "            if filename.startswith('stub'):\n",
    "                logger.debug(f\"Skipping stub asset: {filename}\")\n",
    "                continue\n",
    "\n",
    "            # check if the asset is a debug build\n",
    "            debug = 'debug' in filename.lower() or 'dbg' in filename.lower()\n",
    "\n",
    "            release_info = MagiskRelease(\n",
    "                tag_name=tag_name,\n",
    "                release_name=release_name,\n",
    "                prerelease=prerelease,\n",
    "                debug=debug,\n",
    "                filename=filename,\n",
    "                url=url\n",
    "            )\n",
    "            available_releases.append(release_info)\n",
    "            logger.info(f\"Found Magisk release: {release_info}\")\n",
    "\n",
    "    return available_releases\n",
    "\n",
    "magisk_releases = fetchMagiskReleases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7223dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "magisk_releases_df = pd.DataFrame(magisk_releases)\n",
    "magisk_releases_df\n",
    "\n",
    "magisk_version = \"29.0\"\n",
    "\n",
    "matching_releases = [r for r in magisk_releases if r.tag_name == magisk_version or r.tag_name == f\"v{magisk_version}\"]\n",
    "\n",
    "# i don't want debug builds\n",
    "matching_releases = [r for r in matching_releases if not r.debug]\n",
    "\n",
    "assert len(matching_releases) > 0, f\"No matching releases found for version {magisk_version}\"\n",
    "assert len(matching_releases) == 1, f\"Multiple matching releases found for version {magisk_version}: {matching_releases}\"\n",
    "\n",
    "matching_release = matching_releases[0]\n",
    "download_dir = os.path.join(os.getcwd(), 'downloads')\n",
    "matching_release.download(download_dir, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63180bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixel-ota (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
